{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-CcKpTQYXtH"
   },
   "source": [
    "# Basic chatbot using Keras and NLTK\n",
    "\n",
    "### Skills Demonstrated: \n",
    "\n",
    "*   Natural Language Processing\n",
    "*   Deep Learning & Data Preprocessing\n",
    "\n",
    "\n",
    "\n",
    "### Tools Used:\n",
    "\n",
    "\n",
    "*   NLTK\n",
    "*   Tensorflow, Keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Introduction \n",
    "\n",
    "A chatbot is smart code that is capable of communicating similar to a human.\n",
    "\n",
    "Chatbots are used a lot in customer interaction, marketing on social network sites and instantly messaging the client.\n",
    "\n",
    "There are two basic types of Natural Language Processing (NLP) chatbot models based on how they are built:\n",
    "\n",
    "Retrieval based. A retrieval-based chatbot uses predefined input patterns and responses. It then uses some type of heuristic approach to select the appropriate response. It is widely used in the industry to make goal-oriented chatbots where we can customize the tone and flow of the chatbot to drive our customers with the best experience.\n",
    "\n",
    "Generative based models are not based on some predefined responses. They are based on seq 2 seq neural networks. It is the same idea as machine translation. In machine translation, we translate the source code from one language to another language but here, we are going to transform input into an output. It needs a large amount of data and it is based on Deep Neural Networks (DNN).\n",
    "\n",
    "\n",
    "## Scope of this chatbot\n",
    "\n",
    "We are going to build a chatbot using deep learning techniques following the retrieval-based concept. The chatbot will be trained on the dataset which contains conversation categories (intents), patterns, and responses. The model uses a Deep Neural Network with a single hidden layer to classify which category the input message belongs to and then the chatbot will select a random response from the list of responses, which have similar meaning.\n",
    "\n",
    "It may be used on websites pertaining to hospital, pharmaceutical online stores etc. or modified to fit completely different purposes. Furthermore, this is just a prototype whose functionality can be greatly expanded in topics it can reply to, depth of conversation, answer variety of questions and so on.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciJv_24AZJrB"
   },
   "source": [
    "###Step 1: Imports \n",
    "\n",
    "Call all the libraries we need for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bEI_-GvOSo7"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3qt_JU-lhlv"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle           #for serialisation\n",
    "import random\n",
    "import numpy as np \n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "nltk.download('punkt')  # dependencies required \n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "path_json = '/Users/Avit/Desktop/chatbot/intents.json'\n",
    "intents = json.loads(open(path_json).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0iQByHpcOjg"
   },
   "source": [
    "### Step-2: Training the chatbot using deep learning using the keras library. \n",
    "Here the 'intents' json file contents are parsed through and lemmatized using NLTK libraries post which the tokens along with their 'intent' tags are trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTvQSMR-b_FL"
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_letters = {'?', '!', '.', ','}\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        word_list = nltk.word_tokenize(pattern)\n",
    "        words.extend(word_list)\n",
    "        documents.append((word_list, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "words = [lemmatizer.lemmatize(word) for word in words if word not in ignore_letters]\n",
    "words = sorted(set(words))\n",
    "classes = sorted(set(classes))\n",
    "\n",
    "pickle.dump(words, open('words.pkl', 'wb')) #savin the lists in a pickle file in the form of binaries\n",
    "pickle.dump(classes, open('classes.pkl', 'wb'))\n",
    "\n",
    "#creating the bow list and the training list\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for document in documents:\n",
    "    bow = []\n",
    "    word_patterns = document[0]\n",
    "    word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
    "    for word in words:\n",
    "        bow.append(1) if word in word_patterns else bow.append(0)\n",
    "        \n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(document[1])] = 1 \n",
    "    training.append([bow, output_row])\n",
    "\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "\n",
    "\n",
    "#building and training the neural network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (len(train_x[0]),), activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(train_y[0]), activation = 'softmax'))\n",
    "\n",
    "sgd = SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov= True)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "\n",
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs = 500, batch_size = 5, verbose =1)\n",
    "model.save('chatbotmodel.h5', hist)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5xSa-Mtaa-Z"
   },
   "source": [
    "### Step 3: Preprocessing the input - Some helper functions \n",
    "\n",
    "For class prediction, we need to provide input in the same way as we did for training. These helper functions perform text preprocessing when the user presses 'Enter' and then predict the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDooP5qP1Ajl"
   },
   "outputs": [],
   "source": [
    "words = pickle.load(open('words.pkl', 'rb'))\n",
    "classes = pickle.load(open('classes.pkl', 'rb'))\n",
    "model = load_model('chatbotmodel.h5')\n",
    "\n",
    "def  clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "\n",
    "def  bag_of_words(sentence):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bow = [0]*len(words)\n",
    "    for w in sentence_words:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == w:\n",
    "                bow[i] = 1\n",
    "    return np.array(bow)\n",
    "\n",
    "\n",
    "def predict_class(sentence):\n",
    "    bag = bag_of_words(sentence)\n",
    "    res = model.predict(np.array([bag]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "\n",
    "    results.sort(key = lambda x: x[1], reverse = True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({'intent': classes[r[0]], 'probability': str(r[1])})\n",
    "    return return_list \n",
    "\n",
    "def get_response(intents_list, intents_json):\n",
    "    tag = intents_list[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if i['tag'] == tag:\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def chatbot_response(text):\n",
    "    ints = predict_class(text)\n",
    "    res = get_response(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: GUI\n",
    "\n",
    "Code for the Graphical User Interface.\n",
    "\n",
    "The GUI uses the tkinter library, which is an Python interface to the Tk GUI toolkit. Tkinter is Python’s de-facto standard GUI.\n",
    "\n",
    "Tasks of the GUI are: (1) Accept the input message from the user and then (2) use the helper functions to get the response from the bot and then (3) display everything in a window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "\n",
    "# send function: add entry to chat window and get chatbot response\n",
    "def send():\n",
    "    # get written message and save to variable\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
    "    # remove message from entry box\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "    \n",
    "    if msg == \"Message\":\n",
    "        # if the user clicks send before entering their own message, \"Message\" gets inserted again\n",
    "        # no prediction/response\n",
    "        EntryBox.insert(END, \"Message\")\n",
    "        pass\n",
    "        # if user clicks send and proper entry\n",
    "    elif msg != '':\n",
    "        # activate chat window and insert message\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"black\", font=(\"Verdana\", 12 ))\n",
    "        \n",
    "        # insert bot response to chat window\n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"Chatbot: \" + res + '\\n\\n')\n",
    "        \n",
    "        # make window read-only again\n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)\n",
    "\n",
    "def clear_search(event):\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "    EntryBox.config(foreground=\"black\", font=(\"Verdana\", 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute this Cell to start the chatbot GUI\n",
    "Here, everything comes together. The different objects on the screen are defined and what functions are executed when they are interacted with. The ChatLog text field’s state is always set to “Normal” for text inserting and afterwards set to “Disabled” so the user cannot interact with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = tk.Tk()\n",
    "base.title(\"Chatbot\")\n",
    "base.geometry(\"400x500\")\n",
    "base.resizable(width=FALSE, height=FALSE)\n",
    "\n",
    "# create chat window\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"10\", width=\"50\", font=\"Arial\",)\n",
    "\n",
    "# initial greeting in chat window\n",
    "ChatLog.config(foreground=\"black\", font=(\"Verdana\", 12 ))\n",
    "ChatLog.insert(END, \"Chatbot: Hello, I'm Avikshit's chatbot! I can help with... \\n\\t- Making conversation \\n\\t- Saying jokes \\n\\n\")\n",
    "\n",
    "# disable window = read-only\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "# bind scrollbar to ChatLog window\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "\n",
    "# create Button to send message\n",
    "SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"9\", height=5,\n",
    "                    bd=0, bg=\"blue\", activebackground=\"gold\",fg='#ffffff',\n",
    "                    command= send )\n",
    "\n",
    "# create the box to enter message\n",
    "EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n",
    "\n",
    "# display a grey text in EntryBox that's removed upon clicking or tab focus\n",
    "EntryBox.insert(END, \"Message\")\n",
    "EntryBox.config(foreground=\"grey\", font=(\"Verdana\", 12))\n",
    "EntryBox.bind(\"<Button-1>\", clear_search)\n",
    "EntryBox.bind(\"<FocusIn>\", clear_search) \n",
    "\n",
    "# place components at given coordinates in window (x=0 y=0 top left corner)\n",
    "scrollbar.place(x=376,y=6, height=386)\n",
    "ChatLog.place(x=6,y=6, height=386, width=370)\n",
    "EntryBox.place(x=6, y=401, height=90, width=265)\n",
    "SendButton.place(x=282, y=401, height=90)\n",
    "\n",
    "base.mainloop()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "chatbot.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
